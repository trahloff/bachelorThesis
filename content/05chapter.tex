
%***************%
\chapter{Requirement Engineering and Operationalization}\label{chp:operationalization}
%***************%

%***************%
\section{Introduction}
%***************%

In the following section, concepts and indices for measuring suitability and viability will be introduced. The insights presented in chapter~\vref{chp:background} will be the foundation for the requirements and operators since the current academic and professional understanding of the topic will be assumed as correct and holistic. The steps from section~\vref{sssec:reqEng} will be shortened for the upcoming sections on suitability and viability, since \textit{System Modeling} will be done in chapter~\vref{chp:prototyping} and validation is discussed in chapter~\vref{chp:suitabilityAssessment} and~\vref{chp:viabilityAssessment} respectively.  

%***************%
\section{Suitability}
%***************%

The author defines \textit{suitability} as the measure of how well the prototype fits the environments demands and tasks characteristics. Quantitatively measurable aspects will be compared directly while disclosing the desirable value. Qualitatively measurable aspects will be discussed and deductively compared in order to study the prototypes' differences. 

\begin{figure}[ht]
    \includegraphics[width=0.7\linewidth]{images/methodology/ttf.jpg}\centering
    \caption
    [Task-Technology-Fit Model]
    {Task-Technology-Fit Model (Source: \cite{Goodhue1995Task-TechnologyPerformance})}
\end{figure}

\subsection{Identification of Requirements / Task Characteristics}

As discussed in chapter~\vref{chp:background}, IoT Event-Stream-Processing entails a distinctive set of task and environment characteristics. It is characterized by an enormously high amount of client nodes that send data in a timely ordered fashion. These messages have to be processed in near real-time to avoid a system wide congestion that would result in a degradation of service and possible loss of messages. The API Gateway's performance is mostly neglectable in a real-world scenario since the computational heavy-lifting is done by the data-consumer, this characteristic results in a requirement for a processing architecture that can seamlessly handle the computational load that is resulting from any data ingress.\\
Since it is often not possible to estimate the exact amount of messages and thevrefore the exact amount of required compute power, the data-consumer's capacity has to \textit{automatically scale} with the load. The data ingress level can vary in short periods of, hence a manual scaling is not desirable.

Consequently, the architecture must be \textit{inherently event-driven}. If not, a fully automated scaling strategy is not possible by definition. Moreover, an event-driven approach results in an architecture that is better equipped to respond to elastic workloads, such as the ones found in IoT environments. As previously discussed, it is necessary to immediately process incoming information in an IoT context to derive valuable insights. An event-driven system is thevrefore well suited for this task because it \textit{minimizes the latency} between the moment of receiving the message and processing it because the information flow is strictly left-to-right. Other alternatives would introduce a lag-time by requiring the processing part of the architecture to query the data storage for new data. 

Equally important is the system's ability to "self-heal", meaning the capability to mitigate components collapse and to to maintain an operational state. This resulting \textit{failure resilience} of data-consumers is vital for an efficient Event-Stream-Processing architecture because a lack thereof will result in massive backpressure on the downstream services and API Gateway and leads to an inevitable system-wide congestion.\\
Tightly related is the tasks demand for a \textit{high throughput}. It can directly derived from the overarching need to avoid a message congestion at any cost. Naturally, a higher throughput is desirable and will lead to an increased performance and overall better suited system for the task.

Lastly, it is a characteristic of IoT Event-Processing-Tasks in a real-world business context, that cost are often calculated in a very granular fashion. Since the IoT system's monetary value is often contingent on the amount of messages processed, it is, from a business perspective, very desirable to have a system which generates costs that are directly correlated to the amount of messages processed, too. Hence, a \textit{dynamic billing based on computation} is a requirement that is not pivotal, but should be considered nonetheless.

\subsection{Specification of Requirements}

The identified requirements are thevrefore as follows:

\begin{enumerate}
    \item \textbf{Automated/Limitless Scaling}\\
        (Qualitatively measured) How does the system behave under increasing load and what are the provisioning strategies?
    \item \textbf{Event-Driven Design}\\
        (Qualitatively measured) Is the system inherently evend-driven?
    \item \textbf{Low Latency}\\
        (Quantitatively measured) How high is the latency between "Message Received" and "Message Processed"?
    \item \textbf{Failure Resilience}\\
        (Qualitatively measured) What happens when a failure occurs? Are safeguards like automatic failover strategies, outage mitigation or self-healing capabilities in place?
    \item \textbf{Message Throughput}\\
        (Quantitatively measured) How high is the achievable message throughput?
\end{enumerate}



%***************%
\section{Viability}
%***************%

\textit{Viability} measures the extent of value-added by the technology in comparison to the cost of operation, development, implementation and so forth. Quantitatively measurable aspects will be compared directly while disclosing the desirable value. Qualitatively measurable aspects will be discussed and deductively compared in order to study the prototypes' differences. 

viability  measures the extent to which the environment or organization is ready fo r the application



\begin{figure}[ht]
    \includegraphics[width=0.7\linewidth]{images/methodology/fvm.jpg}\centering
    \caption
    [Fit-Viability-Model]
    {Fit-Viability-Model (Source: \cite{Liang2007AdoptionModel})}
\end{figure}


\subsection{Identification of Requirements / Task Characteristics}

As discussed in chapter~\vref{chp:background}, \textit{viability} is an important factor when choosing a technology for a system design. Not only does the academic and technical suitability influences the architectures success, the ease of working with the technology is a pivotal aspect that can decide whether the chosen technology fits for task or not.\\
Under the term \textit{Ease of Development} several facets of software engineering requirements can be aggregated. In order to enable the developers to successfully implement the architects vision, a comprehensive and easy to understand documentation for the technology has to be available. Otherwise, the work is often error-prone and an excessive amount of time is needed to understand how to operate the technology. Similarly, a lack of available and extensive tooling can cause major delays in the implementation phase. It is furthermore important to be able to conduct automated testing (e.g., unit, integration, etc.) in order to ensure constantly high software quality throughout the products life-cycle.\\
Likewise, \textit{Ease of Operation} contributes to an overall pleasant and efficient software engineering process. Deployment of the product and the subsequent monitoring has to be easily accessible, cheap and comprehensive. In addition, versioning of the service has to be possible in order to employ DevOps methodologies and enable the operations team to control and rollback the service. Lastly, the performance the service has to be optimizable to ensure an efficient operation of the architecture.\\
Related to \textit{Ease of Development and Deployment}, \textit{Feature Velocity} plays an important role in the decision for a technology from a business perspective since a higher feature velocity directly translates to a decrease on time-to-market which equals a higher market-share and shorter development life-cycles.\\
Controversly discussed, the \textit{Vendor Lock-In} influences the design and operation of any architecture. A high lock-in results in high costs to migrate from the chosen service or technology provider to another option. This can cause high opportunity costs and makes the operation from the developer's perspective more inflexible. \\
Finally, low \textit{Costs} are an important factor when designing a system for obvious reasons. 

\subsection{Specification of Requirements}

\begin{enumerate}
    \item \textbf{Ease of Development}\\
        (Qualitatively measured) Including: Quality/Comprehensiveness of Documentation, Available Tooling, Ease of Testing (Unit, Integration, User Acceptance, etc.), Debugging, ...
    \item \textbf{Ease of Operation}\\
        (Qualitatively measured) Including: Monitoring, Deployment, Versioning, Performance Optimization, ...
    \item \textbf{Feature Velocity}\\
        (Qualitatively measured) How high is the theoretical feature velocity?
    \item \textbf{Low Vendor Lock-In}\\
        (Qualitatively measured) What are the implicit costs to migrate \textit{away} from the serverless platform to another?
    \item \textbf{Cost}\\
        (Quantitatively measured) How high are the costs? Including: Overall Cost of Operation/Ownership, Cost-Control, Ease of Billing/Payment, Total Costs of Maintenance, ...
\end{enumerate}


\section{Requirements Validation}\label{sec:reqVal}

In order to select a set of important system's properties for the prototype evaluation, a quantitative survey was conducted employing a Likert scale. Ten Likert items were derived from the suitability and viability requirement identification in the previous steps. The Likert items are as follows:

\begin{enumerate}[nolistsep]\label{lst:surveyItems}
    \item \textbf{Ease of Development}\\
        Including: Quality/Comprehensiveness of Documentation, Available Tooling, Ease of Testing (Unit, Integration, User Acceptance, etc.), Debugging, ...
    \item \textbf{Ease of Operation}\\
        Including: Monitoring, Deployment, Versioning, Performance Optimization, ...
    \item \textbf{Feature Velocity}
    \item \textbf{Low Vendor Lock-In}
    \item \textbf{Cost}\\
        Including: Overall Cost of Operation/Ownership, Cost-Control, Ease of Billing/Payment, Total Costs of Maintenance, ...
    \item \textbf{Automated/Limitless Scaling}
    \item \textbf{Event-Driven Design}
    \item \textbf{Low Latency}\\
         Message Received - Message Processed
    \item \textbf{Failure Resilience}\\
         Automatic Failover Strategies, Outage Mitigation, Self-Healing Capabilities
    \item \textbf{Message Throughput}
\end{enumerate}

As bipolar response categories the set \textit{Not Important} and \textit{Very Import} were chosen. In order to prevent respondents from so called "fence-sitting" (choosing the most neutral response option), an even number of scale points was used. To improve the reliability furthermore, the forced-choice response set was extended to six feedback options since a low scale score variability is expected.\autocite{Brill2008LikertScale} Similarly, a set of consecutive integers (i.e., 1, 2, 3, 4, 5, 6) was used to label the response scale to emphasize the equidistance between the options. Consequently, this setup results in an ordinal level of measurement, which can be processed by parametric statistics to gain insights on how to construct the test cases. \\
The evaluation of this survey's results will lead to one distinct system characteristic each for \textit{suitability} and \textit{viability}. For each domain, the system property with the highest measured importance among the respondents will be chosen due to the limited time and scope of this research. \\
Likert scales are subject to several academic inaccuracies and response distortion. To begin with, central tendency (respondents tend to choose the most neutral and thevrefore most central response option\autocite{Schumacker2013CentralDispersion}) can occur due to the interviewees impulse to avoid extreme response categories. In addition, acquiescence bias can distort the results. It refers to the tendency of respondents to choose to agree with statements because of the intention to choose what they think is the appropriate or objectively "correct" answer.\autocite{Costello2015AcquiescenceEducation}\highcomma\autocite{Aichholzer2015ControllingTests} Similarly, social desirability bias may occur when respondents try to portray themselves in a specific way.\autocite{Grimm2010SocialBias} \\
Since this survey does not address personal, moral or ethical topics, the biases mentioned above will not have a drastic influence on the results. Their impact is thevrefore neglectable. 


%***************%
\subsection{Results}
%***************%

The survey was hosted on \url{typeform.com}, utilizing the service's \textit{free} plan that limits to ten question items. The system characteristics described in chapter~\vref{lst:surveyItems} were used to derive Likert items. 
Overall,
55 responses were collected from
57 unique visitors, which corresponds to a
96.49\% completion rate. The average time to complete was 
01:49 (one minute, fourty-nine seconds).
100\% of the respondents answered every question.

\begin{minipage}{\textwidth}
    The results are as follows:
    
    \begin{enumerate}[nolistsep]\label{lst:surveyResults1}
        \item \textit{Automated/Limitless Scaling} Average: 5.1
        \item \textit{Event-Driven Design} Average: 4.6
        \item \textit{Low Latency} Average: 4
        \item \textit{Failure Resilience} Average: 3.2
        \item \textit{Message Throughput} Average: 4.6
        \item \textit{Ease of Development} Average: 4.3
        \item \textit{Ease of Operation} Average: 4.3
        \item \textit{Feature Velocity} Average: 4
        \item \textit{Low Vendor Lock-In} Average: 4.3
        \item \textit{Cost} Average: 4.9
    \end{enumerate}
\end{minipage}

%***************%
\section{Summary}
%***************%

Using the methodology defined in chapter~\vref{sec:approach}, a set of five system characteristics for each the \textit{suitability} and \textit{viability} dimension where identified and specified using the insights gathered through systematic literature review in chapter~\vref{chp:background} starting in chapter~\vref{chp:background}. To validate and select two of these characteristics, a quantitative survey using the Likert scale as a methodological approach was conducted. To avoid any distortion due to non-informed answers, the target group consisted of subject matter experts, experienced software architects and researchers that published on this topic. Particular mentioned should be made of Paul Castro, Vatche Ishakian, Vinod Muthusamy and Aleksander Slominski, whose work has been discussed in chapter~\vref{chp:motivation}. 

Using the two highest voted system characteristic from both the \textit{suitability} and \textit{viability} domain, these two properties will be evaluated:
\begin{enumerate}[nolistsep]
    \item \textbf{Automated/Limitless Scaling}
    \item \textbf{Cost}
\end{enumerate}
